# MLP实现对比项目

本项目实现了两种多层感知机(MLP)的实现方式，并进行了详细的性能对比：
1. 基于NumPy的自定义实现
2. 基于scikit-learn的实现

## 项目结构

```
.
├── MLP_Numpy.py          # 基于NumPy的MLP实现
├── MLP_sklearn.py        # 基于scikit-learn的MLP实现
├── compare_mlp.py        # 模型对比测试脚本
├── show_dataset.py       # MNIST数据集可视化脚本
├── data/                 # MNIST数据集目录
└── results/              # 结果保存目录
    └── YYYYMMDD_HHMMSS/  # 按时间戳组织的实验结果
        ├── mlp_numpy/    # NumPy实现的结果
        │   ├── he/      # He初始化方法的结果
        │   └── random/  # 随机初始化方法的结果
        └── mlp_sklearn/  # sklearn实现的结果
            ├── he/      # He初始化方法的结果
            └── random/  # 随机初始化方法的结果
```

## 功能特点

1. 两种MLP实现：
   - 基于NumPy的自定义实现，支持灵活的层结构和激活函数配置
   - 基于scikit-learn的实现，提供标准化的接口

2. 多种初始化方法：
   - He初始化：由何凯明提出的初始化方法，特别适合ReLU激活函数
   - 随机初始化：使用较小的标准差（0.01）进行随机初始化
   - 支持不同初始化方法的性能对比

3. 数据集可视化：
   - 使用`show_dataset.py`脚本展示MNIST数据集样本
   - 以10x10网格形式展示100个随机样本
   - 每个样本上方显示其真实标签
   - 自动保存高质量可视化结果

4. 完整的性能评估：
   - 准确率（Accuracy）
   - 精确率（Precision）
   - 召回率（Recall）
   - F1分数
   - 混淆矩阵
   - 训练时间
   - 推理时间

5. 训练过程监控：
   - 根据训练轮数（epochs）动态调整评估频率
   - epochs ≤ 100时，每个epoch都计算和显示性能指标
   - epochs > 100时，每10个epoch计算和显示一次
   - 记录完整的训练历史（loss和accuracy）

6. 可视化功能：
   - MNIST数据集样本展示
   - 训练历史曲线（loss和accuracy）
   - 性能指标对比图
   - 混淆矩阵可视化
   - 不同初始化方法的性能对比

## 环境要求

- Python 3.6+
- NumPy
- scikit-learn
- PyTorch (用于数据加载)
- matplotlib
- seaborn

## 使用方法

1. 安装依赖：
```bash
pip install numpy scikit-learn torch matplotlib seaborn
```

2. 查看MNIST数据集样本：
```bash
python show_dataset.py
```

3. 运行对比测试：
```bash
python compare_mlp.py
```

## 实现细节

### 数据预处理
- 使用完整的MNIST训练集（60,000样本）和测试集（10,000样本）
- 数据标准化：使用MNIST数据集的均值和标准差
  - 均值：0.1307
  - 标准差：0.3081

### 数据集可视化
- 随机选择100个样本进行展示
- 使用灰度图显示
- 图片大小为15x15英寸
- 保存为300 DPI的高质量图片
- 结果保存在`results/mnist_samples.png`

### 模型配置
- 网络结构：[784, 128, 64, 10]
- 激活函数：['relu', 'relu', 'softmax']
- 学习率：0.001
- 批大小：256
- 训练轮数：50
- 初始化方法：
  - He初始化：权重标准差为 sqrt(2/n)，其中n为输入维度
  - 随机初始化：权重标准差为0.01

### 训练过程
1. NumPy实现：
   - 使用随机梯度下降（SGD）
   - 每个epoch随机打乱数据
   - 支持批量训练
   - 支持多种初始化方法

2. scikit-learn实现：
   - 使用SGD优化器
   - 每个epoch随机打乱数据
   - 禁用早停机制，确保每个epoch只训练一次
   - 支持多种初始化方法

### 性能评估
- 使用完整的测试集进行评估
- 计算多个评估指标
- 保存详细的评估结果和可视化图表
- 对不同初始化方法的结果进行对比分析

## 结果说明

结果将保存在`results`目录下，按时间戳组织，包含：
1. MNIST数据集样本展示图
2. 性能指标文本文件
3. 混淆矩阵图
4. 训练历史曲线
5. 性能对比图
6. 不同初始化方法的对比结果

每个初始化方法的结果都包含：
- 模型性能指标
- 训练和推理时间
- 训练历史曲线
- 混淆矩阵

## 注意事项

1. 训练时间：
   - 使用完整数据集训练时间较长
   - 建议使用GPU加速（如果可用）

2. 内存使用：
   - 完整数据集需要较大内存
   - 确保系统有足够的内存空间

3. 模型比较：
   - 两个实现使用相同的网络结构和超参数
   - 训练过程完全同步，便于公平比较
   - 支持不同初始化方法的对比

4. 数据集可视化：
   - 每次运行`show_dataset.py`会随机选择不同的样本
   - 可以通过修改`num_samples`参数调整显示的样本数量

5. 初始化方法选择：
   - He初始化通常能获得更好的性能
   - 随机初始化可以作为基准进行对比
   - 可以通过修改`init_methods`列表来选择要测试的初始化方法
